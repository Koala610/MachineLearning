{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import tools as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = ['1.png','2.png','3.png','4.jpg','5.jpg','5.png']\n",
    "imgs = []\n",
    "vises = []\n",
    "\n",
    "for img in img_list:\n",
    "    tmp = cv2.imread(img, 0)\n",
    "    imgs.append(tmp)\n",
    "    tmp = cv2.imread(img)\n",
    "    vises.append(tmp)\n",
    "    #show_image(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET GRADIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient(gray, x = 0, y = 0, useGradient = True):\n",
    "    if useGradient:\n",
    "        \n",
    "        #Finding gradinet\n",
    "        grad = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=x, dy=y, ksize=3)\n",
    "\n",
    "        '''\n",
    "            take absolute value of gradient to use negative gradient\n",
    "        '''\n",
    "        grad = np.absolute(grad)\n",
    "\n",
    "        '''\n",
    "            Normalization of gradient\n",
    "        '''\n",
    "        (minVal, maxVal) = (np.min(grad), np.max(grad)) \n",
    "        if maxVal - minVal > 0:\n",
    "            grad = (255 * ((grad - minVal) / float(maxVal - minVal))).astype(\"uint8\")\n",
    "        else:\n",
    "            grad  = np.zeros(gray.shape, dtype = \"uint8\")\n",
    "\n",
    "    else:\n",
    "        grad = cv2.adaptiveThreshold(  gray,\n",
    "                                        255,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY_INV,\n",
    "                                        11,\n",
    "                                        2)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_imgs = []\n",
    "###\n",
    "for img in imgs:\n",
    "    tmp = getGradient(img,x=1,useGradient = True)\n",
    "    bin_imgs.append(tmp)\n",
    "    #show_image(tmp)\n",
    "    \n",
    "    \n",
    "true_bin_imgs = []\n",
    "###\n",
    "for img in imgs:\n",
    "    tmp = getGradient(img,x=1,useGradient = False)\n",
    "    true_bin_imgs.append(tmp)\n",
    "    #show_image(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "verps = []\n",
    "\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    verp = np.sum(bin_imgs[i], axis=1) / 255 #initially axis = 1\n",
    "    drawed_verp = tl.getDrawProjectionVer(imgs[i], verp)\n",
    "    verps.append([verp,drawed_verp])\n",
    "    #bigImg = tl.concat_hor((imgs[i],drawed_verp))\n",
    "    #show_image(bigImg)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ADAPTIVE FILTER SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_and_hiers = []\n",
    "halfs = []\n",
    "\n",
    "for verp in verps:\n",
    "    half = int(np.max(verp[0]) / 2)\n",
    "    halfs.append(half)\n",
    "    sliceLine = verp[1][:,(half-1):(half+1)]\n",
    "    contours, hierarchy = cv2.findContours(cv2.cvtColor(   sliceLine, \n",
    "                                                           cv2.COLOR_BGR2GRAY), \n",
    "                                                           cv2.RETR_EXTERNAL, \n",
    "                                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cons_and_hiers.append([contours, hierarchy])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_heights = []\n",
    "\n",
    "for ch in cons_and_hiers:\n",
    "    local_heights = []\n",
    "    for cnt in ch[0]:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        local_heights.append(h)\n",
    "    global_heights.append(local_heights)\n",
    "#print(global_heights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medianHeight 31\n",
      "medianHeight 12\n",
      "medianHeight 10\n",
      "medianHeight 10\n",
      "medianHeight 9\n",
      "medianHeight 10\n"
     ]
    }
   ],
   "source": [
    "median_heights = []\n",
    "\n",
    "for heights in global_heights:\n",
    "    median_height = (np.median(np.asarray(heights)) * 1.5).astype(int)\n",
    "    print(\"medianHeight\", median_height)\n",
    "    #median_heights.append(median_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for drawed_verp in verps:\n",
    "    drawed_verp[1] = cv2.line(drawed_verp[1], \n",
    "                      (halfs[cnt],0), \n",
    "                      (halfs[cnt],drawed_verp[1].shape[0]), \n",
    "                      (0,0,255), \n",
    "                      1)\n",
    "    cnt+=1\n",
    "    #print(drawed_verp[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolve peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = []\n",
    "verps_convolved = []\n",
    "drawed_verps_conv = []\n",
    "for median_height in median_heights:\n",
    "    kernel = median_height\n",
    "    kernels.append(kernel)\n",
    "    \n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for kernel in kernels:\n",
    "    cnt1+=1\n",
    "    for verp in verps:\n",
    "        cnt2+=1\n",
    "        if cnt1 == cnt2:\n",
    "            print(kernel)\n",
    "            verp_convolved = np.convolve(verp[0], np.ones((kernel,))/kernel, mode='same')\n",
    "            verps_convolved.append(verp_convolved)\n",
    "        else:\n",
    "            continue\n",
    "    cnt2=0  \n",
    "    \n",
    "cnt1 = 0\n",
    "cnt2 = 0  \n",
    "for img in imgs:\n",
    "    cnt1+=1\n",
    "    for verp_convolved in verps_convolved:\n",
    "        cnt2+=1\n",
    "        if cnt1 == cnt2:\n",
    "            drawed_verp_conv = tl.getDrawProjectionVer(img, verp_convolved) \n",
    "            drawed_verps_conv.append(drawed_verp_conv)\n",
    "        else:\n",
    "            continue\n",
    "    cnt2=0\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1221-fef0db32d6ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mband_P1_ranges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mpeaks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverps_convolved\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mybm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverps_convolved\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "global_band_P1_ranges = []\n",
    "global_peaks = []\n",
    "c1 = 0.2\n",
    "c2 = 0.4\n",
    "args = [30,30,80,13,15,21]\n",
    "\n",
    "args1 = [[0.2,0.4],\n",
    "         [0.2,0.4],\n",
    "         [0.2,0.4],\n",
    "         [0.2,0.4],\n",
    "         [0.2,0.4],\n",
    "         [0.2,0.4]\n",
    "        ]\n",
    "for i in range(len(imgs)):\n",
    "    band_P1_ranges = []\n",
    "    peaks = []\n",
    "    while np.max(verps_convolved[i]) > args[i]:\n",
    "        ybm = np.argmax(verps_convolved[i])\n",
    "\n",
    "        yb0 = tl.findb0(verps_convolved[i], \n",
    "                        ybm, \n",
    "                        args1[i][0] * verps_convolved[i][ybm])\n",
    "        yb1 = tl.findb1(verps_convolved[i], \n",
    "                        ybm, \n",
    "                        args1[i][1] * verps_convolved[i][ybm])\n",
    "        if yb1 - yb0 > median_heights[i]:\n",
    "            band_P1_ranges.append((yb0,yb1))\n",
    "            peaks.append((int(verps_convolved[i][ybm]), ybm))\n",
    "\n",
    "        verps_convolved[i][yb0:yb1] = 0\n",
    "    global_band_P1_ranges.append(band_P1_ranges)\n",
    "    global_peaks.append(peaks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw peaks\n",
    "for i in range(len(imgs)):\n",
    "    for peak in global_peaks[i]:\n",
    "        cv2.circle(drawed_verps_conv[i], peak, 5, (255,0,0), -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bands\n",
    "bandsImgs = []\n",
    "for i in range(len(imgs)):\n",
    "    bandsImg = np.zeros(vises[i].shape, dtype = np.uint8)\n",
    "    for band in global_band_P1_ranges[i]:\n",
    "        yt, yb = band\n",
    "        bandsImg[yt:yb] = [0,255,0]\n",
    "        \n",
    "        horp = np.sum(true_bin_imgs[i][yt:yb], axis=0) / 255 #initially axis = 1\n",
    "        drawed_horp = tl.getDrawProjectionHor(imgs[i], horp)\n",
    "        \n",
    "        kernel = np.ones((8,8),dtype = np.uint8)\n",
    "        drawed_horp = cv2.morphologyEx(drawed_horp,cv2.MORPH_CLOSE,kernel)\n",
    "        \n",
    "        kernel = np.ones((2,2),dtype = np.uint8)\n",
    "        #drawed_horp = cv2.morphologyEx(drawed_horp,cv2.MORPH_OPEN,kernel)\n",
    "        \n",
    "        start = 0\n",
    "        end = 0\n",
    "        for x in range(drawed_horp.shape[1]):\n",
    "            max_y = drawed_horp.shape[0]\n",
    "            max_y-= int(max_y/5)\n",
    "            \n",
    "            max_ys =[int(max_y/50),\n",
    "                   int(max_y/5),\n",
    "                   int(max_y/5),\n",
    "                   int(max_y/5)\n",
    "                   ,int(max_y/5),\n",
    "                   int(max_y/5)]\n",
    "            limit = [\n",
    "                6,\n",
    "                30,\n",
    "                30,\n",
    "                30,\n",
    "                30,\n",
    "                30\n",
    "            ]\n",
    "            cnt = 0\n",
    "            if start == 0:\n",
    "                if (drawed_horp[max_ys[i]][x][0] == 255 and drawed_horp[max_ys[i]][x][1] == 255 and drawed_horp[max_ys[i]][x][2] == 255):\n",
    "                    start = x\n",
    "\n",
    "\n",
    "            else:\n",
    "                if (drawed_horp[max_ys[i]][x][0] == 0 and drawed_horp[max_ys[i]][x][1] == 0 and drawed_horp[max_ys[i]][x][2] == 0):\n",
    "                        end = x\n",
    "                        cnt +=1\n",
    "    \n",
    "\n",
    "            if start != 0 and end != 0:\n",
    "                if(end - start <limit[i]):\n",
    "                    end = 0\n",
    "                else:\n",
    "                    y = bin_imgs[i].shape[0]\n",
    "                    imgs[i][yt:yb,start-1:start+1] = 70\n",
    "                    imgs[i][yt:yb,end-1:end+1] = 30\n",
    "                    #imgs[i] = cv2.line(imgs[i] , (start,yt),(start,yb),(255,255,0),1)\n",
    "                    #imgs[i] = cv2.line(imgs[i] , (end,yt),(end,yb),(0,0,255),1)\n",
    "                    start = 0\n",
    "                    end = 0\n",
    "        \n",
    "        bigImg1 = tl.concat_ver((imgs[i][yt:yb],drawed_horp))\n",
    "        show_image(bigImg1)\n",
    "    bandsImgs.append(bandsImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for i in range(len(imgs)):\n",
    "    vises[i] = cv2.addWeighted(vises[i], 0.6, bandsImgs[i], 0.4, 0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs)):\n",
    "    bigImg1 = tl.concat_hor((imgs[i], verps[i][1], drawed_verps_conv[i]))\n",
    "    fig, ax = plt.subplots(figsize=(50, 50))\n",
    "    ax.imshow(bigImg1, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
